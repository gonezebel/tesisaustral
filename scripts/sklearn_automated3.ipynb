{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando RandomForest...\n",
      "Entrenando XGBoost...\n",
      "Entrenando LightGBM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"c:\\Users\\Gonzalo\\Documents\\GitHub\\00_tesisaustral\\tesisaustral\\tesisaustral\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 282, in _count_physical_cores\n",
      "    raise ValueError(f\"found {cpu_count_physical} physical cores < 1\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.221803 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9839\n",
      "[LightGBM] [Info] Number of data points in the train set: 277330, number of used features: 550\n",
      "[LightGBM] [Info] Start training from score -1.609438\n",
      "[LightGBM] [Info] Start training from score -1.609438\n",
      "[LightGBM] [Info] Start training from score -1.609438\n",
      "[LightGBM] [Info] Start training from score -1.609438\n",
      "[LightGBM] [Info] Start training from score -1.609438\n",
      "Informe guardado como: reporte_modelos_completo.pdf\n",
      "Consumo de memoria registrado en: memory_log.txt\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "from sklearn.impute import SimpleImputer\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.pdfgen import canvas\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "import psutil\n",
    "from datetime import datetime\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ðŸ“… Obtener la fecha y hora de inicio del proceso\n",
    "start_time = datetime.now()\n",
    "timestamp = start_time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# ðŸ“Š Archivos con timestamp\n",
    "memory_log_file = f\"memory_log_{timestamp}.txt\"\n",
    "pdf_file = f\"reporte_modelos_{timestamp}.pdf\"\n",
    "\n",
    "# ðŸ§  FunciÃ³n para registrar el consumo de memoria\n",
    "process = psutil.Process(os.getpid())\n",
    "def log_memory_usage(stage):\n",
    "    memory_info = process.memory_info().rss / (1024 ** 2)  # Convertir a MB\n",
    "    with open(memory_log_file, \"a\") as log_file:\n",
    "        log_file.write(f\"{datetime.now()} - {stage}: {memory_info:.2f} MB\\n\")\n",
    "\n",
    "log_memory_usage(\"Inicio del Proceso\")\n",
    "\n",
    "# ðŸ“¥ Cargar datos\n",
    "parquet_file = r\"C:\\Users\\Gonzalo\\Downloads\\df_triage_encoded.parquet\"\n",
    "df = pd.read_parquet(parquet_file)\n",
    "target_column = 'nivel_triage'\n",
    "\n",
    "# ðŸš€ Preprocesamiento\n",
    "X = df.drop(columns=[target_column])\n",
    "y = df[target_column] - 1  # Ajustar etiquetas para XGBoost\n",
    "\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X_imputed = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_imputed, y, train_size=0.75, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "scaler = RobustScaler()\n",
    "X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns)\n",
    "X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)\n",
    "\n",
    "undersampler = RandomUnderSampler(random_state=42)\n",
    "X_train_balanced, y_train_balanced = undersampler.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "log_memory_usage(\"DespuÃ©s del Preprocesamiento\")\n",
    "\n",
    "# ðŸ” Modelos para GridSearchCV\n",
    "models = {\n",
    "    'RandomForest': {\n",
    "        'model': RandomForestClassifier(random_state=42),\n",
    "        'params': {'n_estimators': [50, 100], 'max_depth': [10, 20, None]}\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'model': XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42),\n",
    "        'params': {'n_estimators': [50, 100], 'max_depth': [3, 6]}\n",
    "    },\n",
    "    'LightGBM': {\n",
    "        'model': LGBMClassifier(random_state=42),\n",
    "        'params': {'n_estimators': [50, 100], 'num_leaves': [31, 50]}\n",
    "    }\n",
    "}\n",
    "\n",
    "# ðŸ“ˆ Resultados\n",
    "results = {}\n",
    "\n",
    "# ðŸš€ Entrenamiento y EvaluaciÃ³n\n",
    "for name, config in models.items():\n",
    "    print(f\"Entrenando {name}...\")\n",
    "    grid = GridSearchCV(config['model'], config['params'], cv=3, scoring='accuracy', n_jobs=-1)\n",
    "    grid.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "    best_model = grid.best_estimator_\n",
    "    y_pred = best_model.predict(X_test_scaled)\n",
    "    y_pred_proba = best_model.predict_proba(X_test_scaled)\n",
    "\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # ðŸŽ¯ Curva ROC\n",
    "    auc_scores = {}\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    for i in range(len(np.unique(y_test))):\n",
    "        fpr, tpr, _ = roc_curve((y_test == i).astype(int), y_pred_proba[:, i])\n",
    "        auc_value = auc(fpr, tpr)\n",
    "        auc_scores[f\"Clase {i+1}\"] = auc_value\n",
    "        plt.plot(fpr, tpr, label=f'Clase {i+1} (AUC = {auc_value:.2f})')\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
    "    plt.xlabel('Tasa de Falsos Positivos (FPR)')\n",
    "    plt.ylabel('Tasa de Verdaderos Positivos (TPR)')\n",
    "    plt.title(f'Curva ROC - {name}')\n",
    "    plt.legend()\n",
    "\n",
    "    roc_plot_path = f\"roc_curve_{name}_{timestamp}.png\"\n",
    "    plt.savefig(roc_plot_path)\n",
    "    plt.close()\n",
    "\n",
    "    # ðŸ”· Matriz de ConfusiÃ³n\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(f'Matriz de ConfusiÃ³n - {name}')\n",
    "    plt.xlabel('Predicho')\n",
    "    plt.ylabel('Real')\n",
    "\n",
    "    conf_matrix_path = f\"conf_matrix_{name}_{timestamp}.png\"\n",
    "    plt.savefig(conf_matrix_path)\n",
    "    plt.close()\n",
    "\n",
    "    results[name] = {\n",
    "        'best_params': grid.best_params_,\n",
    "        'classification_report': report,\n",
    "        'conf_matrix': conf_matrix,\n",
    "        'auc_scores': auc_scores,\n",
    "        'roc_curve_path': roc_plot_path,\n",
    "        'conf_matrix_path': conf_matrix_path\n",
    "    }\n",
    "\n",
    "    log_memory_usage(f\"DespuÃ©s del Entrenamiento de {name}\")\n",
    "\n",
    "# ðŸ† Mejor Modelo segÃºn AUC\n",
    "best_model_by_auc = max(results.items(), key=lambda x: np.mean(list(x[1]['auc_scores'].values())))\n",
    "\n",
    "# â±ï¸ FinalizaciÃ³n\n",
    "end_time = datetime.now()\n",
    "total_duration = (end_time - start_time).total_seconds() / 60\n",
    "\n",
    "# ðŸ“ Generar PDF\n",
    "c = canvas.Canvas(pdf_file, pagesize=letter)\n",
    "c.setFont(\"Helvetica\", 12)\n",
    "c.drawString(100, 750, \"Informe de ComparaciÃ³n de Modelos - Detallado\")\n",
    "\n",
    "# â±ï¸ Tiempos de EjecuciÃ³n\n",
    "c.drawString(100, 730, f\"Hora de Inicio: {start_time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "c.drawString(100, 710, f\"Hora de Fin: {end_time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "c.drawString(100, 690, f\"DuraciÃ³n Total: {total_duration:.2f} minutos\")\n",
    "\n",
    "# ðŸ“Š Resultados por Modelo\n",
    "y_position = 660\n",
    "for model_name, result in results.items():\n",
    "    c.setFont(\"Helvetica-Bold\", 11)\n",
    "    c.drawString(100, y_position, f\"Modelo: {model_name}\")\n",
    "    y_position -= 20\n",
    "\n",
    "    c.setFont(\"Helvetica\", 10)\n",
    "    c.drawString(100, y_position, f\"Mejores ParÃ¡metros: {result['best_params']}\")\n",
    "    y_position -= 20\n",
    "\n",
    "    avg_auc = np.mean(list(result['auc_scores'].values()))\n",
    "    c.drawString(100, y_position, f\"Promedio AUC: {avg_auc:.2f}\")\n",
    "    y_position -= 20\n",
    "\n",
    "    for cls, metrics in result['classification_report'].items():\n",
    "        if isinstance(metrics, dict):\n",
    "            c.drawString(100, y_position, f\"Clase {cls}: PrecisiÃ³n={metrics['precision']:.2f}, Recall={metrics['recall']:.2f}, F1-Score={metrics['f1-score']:.2f}\")\n",
    "            y_position -= 20\n",
    "\n",
    "    # ðŸ“Š Matriz de ConfusiÃ³n y Curva ROC\n",
    "    c.drawImage(result['conf_matrix_path'], 100, y_position - 150, width=300, height=150)\n",
    "    y_position -= 170\n",
    "\n",
    "    c.drawImage(result['roc_curve_path'], 100, y_position - 200, width=300, height=200)\n",
    "    y_position -= 220\n",
    "\n",
    "    if y_position < 150:\n",
    "        c.showPage()\n",
    "        y_position = 750\n",
    "\n",
    "    # ðŸ—‘ï¸ Eliminar ImÃ¡genes Temporales\n",
    "    os.remove(result['conf_matrix_path'])\n",
    "    os.remove(result['roc_curve_path'])\n",
    "\n",
    "# ðŸ† Mejor Modelo\n",
    "c.setFont(\"Helvetica-Bold\", 12)\n",
    "c.drawString(100, y_position, f\"Mejor Modelo por AUC: {best_model_by_auc[0]}\")\n",
    "c.drawString(100, y_position - 20, f\"ParÃ¡metros del Mejor Modelo: {best_model_by_auc[1]['best_params']}\")\n",
    "c.drawString(100, y_position - 40, f\"AUC Promedio: {np.mean(list(best_model_by_auc[1]['auc_scores'].values())):.2f}\")\n",
    "\n",
    "c.save()\n",
    "\n",
    "log_memory_usage(\"Fin del Proceso\")\n",
    "\n",
    "# ðŸ“¦ Resultados Finales\n",
    "print(f\"Informe guardado como: {pdf_file}\")\n",
    "print(f\"Consumo de memoria registrado en: {memory_log_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tesisaustral",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

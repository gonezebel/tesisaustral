{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Procesando: C:\\Users\\Administrador\\Documents\\PythonScripts\\Tesis\\tesisaustral\\outputs\\experiments\\train_test_splits_20250224_221733\\MaxAbs_full_full\\X_train_MaxAbs_full_full.parquet\n",
      "Calculando medianas...\n",
      "Calculando pesos de clase...\n",
      "Selección inicial de características...\n",
      "Época 1 - Loss: 0.8992 | Test Acc: 0.74 | Test F1: 0.68\n",
      "Época 2 - Loss: 0.8934 | Test Acc: 0.74 | Test F1: 0.69\n",
      "Época 3 - Loss: 0.8925 | Test Acc: 0.74 | Test F1: 0.69\n",
      "Época 4 - Loss: 0.8921 | Test Acc: 0.74 | Test F1: 0.69\n",
      "Época 5 - Loss: 0.8920 | Test Acc: 0.74 | Test F1: 0.69\n",
      "✅ Mejor modelo en época 5 - F1: 0.69\n",
      "Distribución de clases en el conjunto de prueba: {4: 31091, 1: 31091, 5: 31090, 3: 31090, 2: 31090}\n",
      "✅ Procesado correctamente\n",
      "\n",
      "Procesando: C:\\Users\\Administrador\\Documents\\PythonScripts\\Tesis\\tesisaustral\\outputs\\experiments\\train_test_splits_20250224_221733\\MaxAbs_Linear_selected\\X_train_MaxAbs_Linear_selected.parquet\n",
      "Calculando medianas...\n",
      "Calculando pesos de clase...\n",
      "Selección inicial de características...\n",
      "Época 1 - Loss: 0.9009 | Test Acc: 0.72 | Test F1: 0.67\n",
      "Época 2 - Loss: 0.8954 | Test Acc: 0.73 | Test F1: 0.68\n",
      "Época 3 - Loss: 0.8945 | Test Acc: 0.73 | Test F1: 0.68\n",
      "Época 4 - Loss: 0.8942 | Test Acc: 0.73 | Test F1: 0.68\n",
      "Época 5 - Loss: 0.8940 | Test Acc: 0.73 | Test F1: 0.68\n",
      "✅ Mejor modelo en época 5 - F1: 0.68\n",
      "Distribución de clases en el conjunto de prueba: {4: 31091, 1: 31091, 5: 31090, 3: 31090, 2: 31090}\n",
      "✅ Procesado correctamente\n",
      "\n",
      "Procesando: C:\\Users\\Administrador\\Documents\\PythonScripts\\Tesis\\tesisaustral\\outputs\\experiments\\train_test_splits_20250224_221733\\MaxAbs_Model-Based_selected\\X_train_MaxAbs_Model-Based_selected.parquet\n",
      "Calculando medianas...\n",
      "Calculando pesos de clase...\n",
      "Selección inicial de características...\n",
      "Época 1 - Loss: 0.8791 | Test Acc: 0.78 | Test F1: 0.72\n",
      "Época 2 - Loss: 0.8727 | Test Acc: 0.78 | Test F1: 0.72\n",
      "Época 3 - Loss: 0.8720 | Test Acc: 0.78 | Test F1: 0.72\n",
      "Época 4 - Loss: 0.8718 | Test Acc: 0.78 | Test F1: 0.72\n",
      "Época 5 - Loss: 0.8717 | Test Acc: 0.78 | Test F1: 0.72\n",
      "✅ Mejor modelo en época 5 - F1: 0.72\n",
      "Distribución de clases en el conjunto de prueba: {4: 31091, 1: 31091, 5: 31090, 3: 31090, 2: 31090}\n",
      "✅ Procesado correctamente\n",
      "\n",
      "Procesando: C:\\Users\\Administrador\\Documents\\PythonScripts\\Tesis\\tesisaustral\\outputs\\experiments\\train_test_splits_20250224_221733\\MaxAbs_Nonlinear_selected\\X_train_MaxAbs_Nonlinear_selected.parquet\n",
      "Calculando medianas...\n",
      "Calculando pesos de clase...\n",
      "Selección inicial de características...\n",
      "Época 1 - Loss: 0.9008 | Test Acc: 0.72 | Test F1: 0.67\n",
      "Época 2 - Loss: 0.8953 | Test Acc: 0.73 | Test F1: 0.68\n",
      "Época 3 - Loss: 0.8944 | Test Acc: 0.73 | Test F1: 0.68\n",
      "Época 4 - Loss: 0.8940 | Test Acc: 0.73 | Test F1: 0.68\n",
      "Época 5 - Loss: 0.8939 | Test Acc: 0.73 | Test F1: 0.68\n",
      "✅ Mejor modelo en época 5 - F1: 0.68\n",
      "Distribución de clases en el conjunto de prueba: {4: 31091, 1: 31091, 5: 31090, 3: 31090, 2: 31090}\n",
      "✅ Procesado correctamente\n",
      "\n",
      "Procesando: C:\\Users\\Administrador\\Documents\\PythonScripts\\Tesis\\tesisaustral\\outputs\\experiments\\train_test_splits_20250224_221733\\MinMax_full_full\\X_train_MinMax_full_full.parquet\n",
      "Calculando medianas...\n",
      "Calculando pesos de clase...\n",
      "Selección inicial de características...\n",
      "Época 1 - Loss: 0.8510 | Test Acc: 0.79 | Test F1: 0.73\n",
      "Época 2 - Loss: 0.8468 | Test Acc: 0.79 | Test F1: 0.73\n",
      "Época 3 - Loss: 0.8462 | Test Acc: 0.79 | Test F1: 0.73\n",
      "Época 4 - Loss: 0.8461 | Test Acc: 0.79 | Test F1: 0.73\n",
      "Época 5 - Loss: 0.8460 | Test Acc: 0.79 | Test F1: 0.73\n",
      "✅ Mejor modelo en época 5 - F1: 0.73\n",
      "Distribución de clases en el conjunto de prueba: {4: 31091, 1: 31091, 5: 31090, 3: 31090, 2: 31090}\n",
      "✅ Procesado correctamente\n",
      "\n",
      "Procesando: C:\\Users\\Administrador\\Documents\\PythonScripts\\Tesis\\tesisaustral\\outputs\\experiments\\train_test_splits_20250224_221733\\MinMax_Linear_selected\\X_train_MinMax_Linear_selected.parquet\n",
      "Calculando medianas...\n",
      "Calculando pesos de clase...\n",
      "Selección inicial de características...\n",
      "Época 1 - Loss: 0.8531 | Test Acc: 0.79 | Test F1: 0.73\n",
      "Época 2 - Loss: 0.8481 | Test Acc: 0.79 | Test F1: 0.73\n",
      "Época 3 - Loss: 0.8476 | Test Acc: 0.79 | Test F1: 0.73\n",
      "Época 4 - Loss: 0.8474 | Test Acc: 0.79 | Test F1: 0.73\n",
      "Época 5 - Loss: 0.8473 | Test Acc: 0.79 | Test F1: 0.73\n",
      "✅ Mejor modelo en época 5 - F1: 0.73\n",
      "Distribución de clases en el conjunto de prueba: {4: 31091, 1: 31091, 5: 31090, 3: 31090, 2: 31090}\n",
      "✅ Procesado correctamente\n",
      "\n",
      "Procesando: C:\\Users\\Administrador\\Documents\\PythonScripts\\Tesis\\tesisaustral\\outputs\\experiments\\train_test_splits_20250224_221733\\MinMax_Model-Based_selected\\X_train_MinMax_Model-Based_selected.parquet\n",
      "Calculando medianas...\n",
      "Calculando pesos de clase...\n",
      "Selección inicial de características...\n",
      "Época 1 - Loss: 0.8158 | Test Acc: 0.79 | Test F1: 0.73\n",
      "Época 2 - Loss: 0.8118 | Test Acc: 0.79 | Test F1: 0.73\n",
      "Época 3 - Loss: 0.8115 | Test Acc: 0.79 | Test F1: 0.73\n",
      "Época 4 - Loss: 0.8114 | Test Acc: 0.79 | Test F1: 0.73\n",
      "Época 5 - Loss: 0.8114 | Test Acc: 0.79 | Test F1: 0.73\n",
      "✅ Mejor modelo en época 5 - F1: 0.73\n",
      "Distribución de clases en el conjunto de prueba: {4: 31091, 1: 31091, 5: 31090, 3: 31090, 2: 31090}\n",
      "✅ Procesado correctamente\n",
      "\n",
      "Procesando: C:\\Users\\Administrador\\Documents\\PythonScripts\\Tesis\\tesisaustral\\outputs\\experiments\\train_test_splits_20250224_221733\\MinMax_Nonlinear_selected\\X_train_MinMax_Nonlinear_selected.parquet\n",
      "Calculando medianas...\n",
      "Calculando pesos de clase...\n",
      "Selección inicial de características...\n",
      "Época 1 - Loss: 0.8542 | Test Acc: 0.79 | Test F1: 0.73\n",
      "Época 2 - Loss: 0.8497 | Test Acc: 0.79 | Test F1: 0.73\n",
      "Época 3 - Loss: 0.8491 | Test Acc: 0.79 | Test F1: 0.73\n",
      "Época 4 - Loss: 0.8490 | Test Acc: 0.79 | Test F1: 0.73\n",
      "Época 5 - Loss: 0.8489 | Test Acc: 0.79 | Test F1: 0.73\n",
      "✅ Mejor modelo en época 5 - F1: 0.73\n",
      "Distribución de clases en el conjunto de prueba: {4: 31091, 1: 31091, 5: 31090, 3: 31090, 2: 31090}\n",
      "✅ Procesado correctamente\n",
      "\n",
      "Procesando: C:\\Users\\Administrador\\Documents\\PythonScripts\\Tesis\\tesisaustral\\outputs\\experiments\\train_test_splits_20250224_221733\\NoNorm_full_full\\X_train_NoNorm_full_full.parquet\n",
      "Calculando medianas...\n",
      "Calculando pesos de clase...\n",
      "Selección inicial de características...\n",
      "Error procesando C:\\Users\\Administrador\\Documents\\PythonScripts\\Tesis\\tesisaustral\\outputs\\experiments\\train_test_splits_20250224_221733\\NoNorm_full_full\\X_train_NoNorm_full_full.parquet: Input contains NaN.\n",
      "\n",
      "Procesando: C:\\Users\\Administrador\\Documents\\PythonScripts\\Tesis\\tesisaustral\\outputs\\experiments\\train_test_splits_20250224_221733\\NoNorm_Linear_selected\\X_train_NoNorm_Linear_selected.parquet\n",
      "Calculando medianas...\n",
      "Calculando pesos de clase...\n",
      "Selección inicial de características...\n",
      "Error procesando C:\\Users\\Administrador\\Documents\\PythonScripts\\Tesis\\tesisaustral\\outputs\\experiments\\train_test_splits_20250224_221733\\NoNorm_Linear_selected\\X_train_NoNorm_Linear_selected.parquet: Input contains NaN.\n",
      "\n",
      "Procesando: C:\\Users\\Administrador\\Documents\\PythonScripts\\Tesis\\tesisaustral\\outputs\\experiments\\train_test_splits_20250224_221733\\NoNorm_Model-Based_selected\\X_train_NoNorm_Model-Based_selected.parquet\n",
      "Calculando medianas...\n",
      "Calculando pesos de clase...\n",
      "Selección inicial de características...\n",
      "Época 1 - Loss: 5.9100 | Test Acc: 0.32 | Test F1: 0.19\n",
      "Época 2 - Loss: 6.0447 | Test Acc: 0.37 | Test F1: 0.22\n",
      "Época 3 - Loss: 5.5578 | Test Acc: 0.40 | Test F1: 0.24\n",
      "Época 4 - Loss: 6.0229 | Test Acc: 0.36 | Test F1: 0.21\n",
      "Época 5 - Loss: 6.4217 | Test Acc: 0.41 | Test F1: 0.25\n",
      "✅ Mejor modelo en época 5 - F1: 0.25\n",
      "Distribución de clases en el conjunto de prueba: {4: 31091, 1: 31091, 5: 31090, 3: 31090, 2: 31090}\n",
      "✅ Procesado correctamente\n",
      "\n",
      "Procesando: C:\\Users\\Administrador\\Documents\\PythonScripts\\Tesis\\tesisaustral\\outputs\\experiments\\train_test_splits_20250224_221733\\NoNorm_Nonlinear_selected\\X_train_NoNorm_Nonlinear_selected.parquet\n",
      "Calculando medianas...\n",
      "Calculando pesos de clase...\n",
      "Selección inicial de características...\n",
      "Error procesando C:\\Users\\Administrador\\Documents\\PythonScripts\\Tesis\\tesisaustral\\outputs\\experiments\\train_test_splits_20250224_221733\\NoNorm_Nonlinear_selected\\X_train_NoNorm_Nonlinear_selected.parquet: Input contains NaN.\n",
      "\n",
      "Procesando: C:\\Users\\Administrador\\Documents\\PythonScripts\\Tesis\\tesisaustral\\outputs\\experiments\\train_test_splits_20250224_221733\\Robust_Linear_selected\\X_train_Robust_Linear_selected.parquet\n",
      "Calculando medianas...\n",
      "Calculando pesos de clase...\n",
      "Selección inicial de características...\n",
      "Época 1 - Loss: 0.7665 | Test Acc: 0.79 | Test F1: 0.73\n",
      "Época 2 - Loss: 0.7672 | Test Acc: 0.79 | Test F1: 0.73\n",
      "Época 3 - Loss: 0.7671 | Test Acc: 0.79 | Test F1: 0.73\n",
      "Época 4 - Loss: 0.7671 | Test Acc: 0.79 | Test F1: 0.73\n",
      "Época 5 - Loss: 0.7671 | Test Acc: 0.79 | Test F1: 0.73\n",
      "✅ Mejor modelo en época 5 - F1: 0.73\n",
      "Distribución de clases en el conjunto de prueba: {4: 31091, 1: 31091, 5: 31090, 3: 31090, 2: 31090}\n",
      "✅ Procesado correctamente\n",
      "\n",
      "Procesando: C:\\Users\\Administrador\\Documents\\PythonScripts\\Tesis\\tesisaustral\\outputs\\experiments\\train_test_splits_20250224_221733\\Robust_Model-Based_selected\\X_train_Robust_Model-Based_selected.parquet\n",
      "Calculando medianas...\n",
      "Calculando pesos de clase...\n",
      "Selección inicial de características...\n",
      "Época 1 - Loss: 0.7641 | Test Acc: 0.80 | Test F1: 0.73\n",
      "Época 2 - Loss: 0.7640 | Test Acc: 0.80 | Test F1: 0.73\n",
      "Época 3 - Loss: 0.7640 | Test Acc: 0.80 | Test F1: 0.73\n",
      "Época 4 - Loss: 0.7640 | Test Acc: 0.80 | Test F1: 0.73\n",
      "Época 5 - Loss: 0.7640 | Test Acc: 0.80 | Test F1: 0.73\n",
      "✅ Mejor modelo en época 5 - F1: 0.73\n",
      "Distribución de clases en el conjunto de prueba: {4: 31091, 1: 31091, 5: 31090, 3: 31090, 2: 31090}\n",
      "✅ Procesado correctamente\n",
      "\n",
      "Procesando: C:\\Users\\Administrador\\Documents\\PythonScripts\\Tesis\\tesisaustral\\outputs\\experiments\\train_test_splits_20250224_221733\\Robust_Nonlinear_selected\\X_train_Robust_Nonlinear_selected.parquet\n",
      "Calculando medianas...\n",
      "Calculando pesos de clase...\n",
      "Selección inicial de características...\n",
      "Época 1 - Loss: 0.7675 | Test Acc: 0.79 | Test F1: 0.73\n",
      "Época 2 - Loss: 0.7678 | Test Acc: 0.79 | Test F1: 0.73\n",
      "Época 3 - Loss: 0.7677 | Test Acc: 0.79 | Test F1: 0.73\n",
      "Época 4 - Loss: 0.7677 | Test Acc: 0.79 | Test F1: 0.73\n",
      "Época 5 - Loss: 0.7677 | Test Acc: 0.79 | Test F1: 0.73\n",
      "✅ Mejor modelo en época 5 - F1: 0.73\n",
      "Distribución de clases en el conjunto de prueba: {4: 31091, 1: 31091, 5: 31090, 3: 31090, 2: 31090}\n",
      "✅ Procesado correctamente\n",
      "\n",
      "Procesando: C:\\Users\\Administrador\\Documents\\PythonScripts\\Tesis\\tesisaustral\\outputs\\experiments\\train_test_splits_20250224_221733\\Standard_Linear_selected\\X_train_Standard_Linear_selected.parquet\n",
      "Calculando medianas...\n",
      "Calculando pesos de clase...\n",
      "Selección inicial de características...\n",
      "Época 1 - Loss: 0.9116 | Test Acc: 0.59 | Test F1: 0.49\n",
      "Época 2 - Loss: 0.8976 | Test Acc: 0.59 | Test F1: 0.49\n",
      "Época 3 - Loss: 0.8906 | Test Acc: 0.59 | Test F1: 0.49\n",
      "Época 4 - Loss: 0.9254 | Test Acc: 0.59 | Test F1: 0.49\n",
      "Época 5 - Loss: 0.9238 | Test Acc: 0.59 | Test F1: 0.49\n",
      "✅ Mejor modelo en época 5 - F1: 0.49\n",
      "Distribución de clases en el conjunto de prueba: {4: 31091, 1: 31091, 5: 31090, 3: 31090, 2: 31090}\n",
      "✅ Procesado correctamente\n",
      "\n",
      "Procesando: C:\\Users\\Administrador\\Documents\\PythonScripts\\Tesis\\tesisaustral\\outputs\\experiments\\train_test_splits_20250224_221733\\Standard_Model-Based_selected\\X_train_Standard_Model-Based_selected.parquet\n",
      "Calculando medianas...\n",
      "Calculando pesos de clase...\n",
      "Selección inicial de características...\n",
      "Época 1 - Loss: 0.8084 | Test Acc: 0.59 | Test F1: 0.49\n",
      "Época 2 - Loss: 0.8050 | Test Acc: 0.59 | Test F1: 0.49\n",
      "Época 3 - Loss: 0.8047 | Test Acc: 0.59 | Test F1: 0.49\n",
      "Época 4 - Loss: 0.8046 | Test Acc: 0.59 | Test F1: 0.49\n",
      "Época 5 - Loss: 0.8044 | Test Acc: 0.59 | Test F1: 0.49\n",
      "✅ Mejor modelo en época 5 - F1: 0.49\n",
      "Distribución de clases en el conjunto de prueba: {4: 31091, 1: 31091, 5: 31090, 3: 31090, 2: 31090}\n",
      "✅ Procesado correctamente\n",
      "\n",
      "Procesando: C:\\Users\\Administrador\\Documents\\PythonScripts\\Tesis\\tesisaustral\\outputs\\experiments\\train_test_splits_20250224_221733\\Standard_Nonlinear_selected\\X_train_Standard_Nonlinear_selected.parquet\n",
      "Calculando medianas...\n",
      "Calculando pesos de clase...\n",
      "Selección inicial de características...\n",
      "Época 1 - Loss: 0.8829 | Test Acc: 0.59 | Test F1: 0.49\n",
      "Época 2 - Loss: 0.8929 | Test Acc: 0.59 | Test F1: 0.49\n",
      "Época 3 - Loss: 0.8849 | Test Acc: 0.59 | Test F1: 0.49\n",
      "Época 4 - Loss: 0.8908 | Test Acc: 0.59 | Test F1: 0.49\n",
      "Época 5 - Loss: 0.8933 | Test Acc: 0.59 | Test F1: 0.49\n",
      "✅ Mejor modelo en época 5 - F1: 0.49\n",
      "Distribución de clases en el conjunto de prueba: {4: 31091, 1: 31091, 5: 31090, 3: 31090, 2: 31090}\n",
      "✅ Procesado correctamente\n",
      "\n",
      "Reportes generados:\n",
      "CSV: C:\\Users\\Administrador\\Documents\\PythonScripts\\Tesis\\tesisaustral\\outputs\\experiments\\train_test_splits_20250224_221733\\reportes_modelos\\metricas_completas_20250226_232341.csv\n",
      "PDF: C:\\Users\\Administrador\\Documents\\PythonScripts\\Tesis\\tesisaustral\\outputs\\experiments\\train_test_splits_20250224_221733\\reportes_modelos\\reporte_completo_20250226_232341.pdf\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import psutil\n",
    "import pyarrow.parquet as pq\n",
    "from datetime import datetime\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, roc_curve, auc, log_loss,\n",
    "    accuracy_score, f1_score, precision_score, recall_score\n",
    ")\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.pdfgen import canvas\n",
    "from collections import defaultdict\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def train_and_evaluate_model(X_train_path, y_train_path, X_test_path, y_test_path):\n",
    "    \"\"\"Entrena y evalúa el modelo con mejoras para optimizar el aprendizaje\"\"\"\n",
    "    start_time = datetime.now()\n",
    "    process = psutil.Process(os.getpid())\n",
    "    mem_before = process.memory_info().rss / (1024 ** 3)\n",
    "    \n",
    "    try:\n",
    "        # 1. Cálculo eficiente de medianas en batches (para imputación de NaN si es necesario)\n",
    "        print(\"Calculando medianas...\")\n",
    "        median_values = None\n",
    "        total_rows = 0\n",
    "        parquet_file = pq.ParquetFile(X_train_path)\n",
    "        \n",
    "        for batch in parquet_file.iter_batches(batch_size=1000):\n",
    "            chunk = batch.to_pandas().astype('float32')\n",
    "            if median_values is None:\n",
    "                median_values = chunk.median() * len(chunk)\n",
    "                total_rows = len(chunk)\n",
    "            else:\n",
    "                median_values += chunk.median() * len(chunk)\n",
    "                total_rows += len(chunk)\n",
    "        \n",
    "        median_values /= total_rows\n",
    "\n",
    "        # 2. Cálculo mejorado de pesos de clase\n",
    "        print(\"Calculando pesos de clase...\")\n",
    "        class_counts = defaultdict(int)\n",
    "        y_parquet = pq.ParquetFile(y_train_path)\n",
    "        \n",
    "        for batch in y_parquet.iter_batches(batch_size=1000):\n",
    "            chunk = batch.to_pandas().squeeze()\n",
    "            counts = chunk.value_counts()\n",
    "            for cls, count in counts.items():\n",
    "                class_counts[cls] += count\n",
    "        \n",
    "        total_samples = sum(class_counts.values())\n",
    "        class_weights = {cls: total_samples / (len(class_counts) * count * 0.5)  # Ajuste para clases minoritarias\n",
    "                        for cls, count in class_counts.items()}\n",
    "\n",
    "        # 3. Cargar y procesar datos de test\n",
    "        X_test = pq.read_table(X_test_path).to_pandas().astype('float32').fillna(median_values)\n",
    "        y_test = pq.read_table(y_test_path).to_pandas().squeeze()\n",
    "\n",
    "        # 4. Verificar que las columnas de entrenamiento y prueba coincidan\n",
    "        X_sample = pq.read_table(X_train_path).to_pandas().sample(n=5000, random_state=42)\n",
    "        y_sample = pq.read_table(y_train_path).to_pandas().squeeze().loc[X_sample.index]\n",
    "\n",
    "        # Asegurarse de que X_test tenga las mismas columnas que X_sample\n",
    "        missing_columns = set(X_sample.columns) - set(X_test.columns)\n",
    "        if missing_columns:\n",
    "            print(f\"Advertencia: Columnas faltantes en X_test: {missing_columns}. Rellenando con 0.\")\n",
    "            for col in missing_columns:\n",
    "                X_test[col] = 0  # Rellenar con 0 o NaN según sea necesario\n",
    "\n",
    "        # 5. Selección de características\n",
    "        print(\"Selección inicial de características...\")\n",
    "        selector = SelectKBest(f_classif, k=min(100, X_sample.shape[1]))\n",
    "        selector.fit(X_sample.fillna(median_values), y_sample)\n",
    "        selected_features = selector.get_support(indices=True)\n",
    "\n",
    "        # 6. Configuración optimizada del modelo\n",
    "        model = SGDClassifier(\n",
    "            loss='log_loss',\n",
    "            penalty='elasticnet',\n",
    "            alpha=0.0001,          # Reducción de regularización\n",
    "            l1_ratio=0.3,          # Balance L1/L2\n",
    "            learning_rate='adaptive', # Tasa de aprendizaje adaptable\n",
    "            eta0=0.1,              # Tasa de aprendizaje inicial\n",
    "            power_t=0.2,\n",
    "            class_weight=class_weights,\n",
    "            max_iter=1000,\n",
    "            tol=1e-5,\n",
    "            random_state=42,\n",
    "            warm_start=True\n",
    "        )\n",
    "\n",
    "        # 7. Entrenamiento con monitoreo mejorado\n",
    "        mem_tracking = []\n",
    "        best_loss = float('inf')\n",
    "        patience = 5\n",
    "        no_improvement = 0\n",
    "        batch_size = 1000\n",
    "        smote = SMOTE(sampling_strategy='auto', k_neighbors=3, random_state=42)\n",
    "        \n",
    "        # 8. Ciclo de entrenamiento mejorado\n",
    "        for epoch in range(50):  # Máximo de épocas reducido\n",
    "            epoch_loss = 0.0\n",
    "            batch_count = 0\n",
    "            X_file = pq.ParquetFile(X_train_path)\n",
    "            y_file = pq.ParquetFile(y_train_path)\n",
    "            \n",
    "            for X_batch, y_batch in zip(X_file.iter_batches(), y_file.iter_batches()):\n",
    "                # Procesamiento del batch\n",
    "                X_train = X_batch.to_pandas().astype('float32').fillna(median_values).iloc[:, selected_features]\n",
    "                y_train = y_batch.to_pandas().squeeze()\n",
    "                \n",
    "                # Aplicar SMOTE en cada batch\n",
    "                try:\n",
    "                    X_res, y_res = smote.fit_resample(X_train, y_train)\n",
    "                except ValueError:\n",
    "                    X_res, y_res = X_train, y_train\n",
    "                \n",
    "                # Entrenamiento y cálculo de métricas\n",
    "                model.partial_fit(X_res, y_res, classes=np.unique(y_sample))\n",
    "                y_proba_train = model.predict_proba(X_res)\n",
    "                batch_loss = log_loss(y_res, y_proba_train)\n",
    "                \n",
    "                epoch_loss += batch_loss\n",
    "                batch_count += 1\n",
    "                mem_tracking.append(process.memory_info().rss / (1024 ** 3))\n",
    "            \n",
    "            # Cálculo de métricas de evaluación\n",
    "            y_pred_test = model.predict(X_test.iloc[:, selected_features])\n",
    "            test_acc = accuracy_score(y_test, y_pred_test)\n",
    "            test_f1 = f1_score(y_test, y_pred_test, average='macro')\n",
    "            test_precision = precision_score(y_test, y_pred_test, average='macro')\n",
    "            test_recall = recall_score(y_test, y_pred_test, average='macro')\n",
    "            \n",
    "            avg_epoch_loss = epoch_loss / batch_count\n",
    "            print(f\"Época {epoch+1} - Loss: {avg_epoch_loss:.4f} | Test Acc: {test_acc:.2f} | Test F1: {test_f1:.2f}\")\n",
    "            \n",
    "            # Early stopping con mejora en métricas de test\n",
    "            if test_f1 > best_loss:\n",
    "                best_loss = test_f1\n",
    "                no_improvement = 0\n",
    "            else:\n",
    "                no_improvement += 1\n",
    "                \n",
    "            if no_improvement >= patience:\n",
    "                print(f\"✅ Mejor modelo en época {epoch+1} - F1: {test_f1:.2f}\")\n",
    "                break\n",
    "\n",
    "        # 9. Evaluación final\n",
    "        y_pred = model.predict(X_test.iloc[:, selected_features])\n",
    "        y_proba = model.predict_proba(X_test.iloc[:, selected_features])\n",
    "        \n",
    "        # Verificar que y_proba no contenga NaN o infinitos\n",
    "        if np.isnan(y_proba).any() or np.isinf(y_proba).any():\n",
    "            raise ValueError(\"Las probabilidades predichas contienen NaN o infinitos. Revisa el entrenamiento del modelo.\")\n",
    "        \n",
    "        # Verificar la distribución de clases en el conjunto de prueba\n",
    "        class_distribution_test = y_test.value_counts()\n",
    "        print(\"Distribución de clases en el conjunto de prueba:\", class_distribution_test.to_dict())\n",
    "        \n",
    "        # Filtrar clases con menos de 2 muestras\n",
    "        valid_classes = class_distribution_test[class_distribution_test >= 2].index\n",
    "        \n",
    "        # Calcular la matriz de confusión\n",
    "        conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "        \n",
    "        # Generar curvas ROC para todas las clases\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        auc_scores = {}\n",
    "        for i in valid_classes:\n",
    "            try:\n",
    "                # Ajustar el índice para coincidir con la columna de y_proba\n",
    "                col_idx = i - 1  # Restar 1 para convertir de índice 1-5 a índice 0-4\n",
    "                fpr, tpr, _ = roc_curve((y_test == i).astype(int), y_proba[:, col_idx])\n",
    "                auc_value = auc(fpr, tpr)\n",
    "                auc_scores[f\"Clase {i}\"] = auc_value\n",
    "                plt.plot(fpr, tpr, label=f'Clase {i} (AUC = {auc_value:.2f})')\n",
    "            except ValueError as e:\n",
    "                print(f\"Error calculando AUC para la clase {i}: {str(e)}\")\n",
    "                auc_scores[f\"Clase {i}\"] = np.nan\n",
    "\n",
    "        # Verificar si se pudo calcular al menos un AUC válido\n",
    "        if not auc_scores or all(np.isnan(value) for value in auc_scores.values()):\n",
    "            print(\"No se pudo calcular el AUC para ninguna clase. Generando gráfico vacío.\")\n",
    "            plt.text(0.5, 0.5, 'No se pudo calcular el AUC para ninguna clase', ha='center', va='center')\n",
    "        \n",
    "        plt.title('Curvas ROC')\n",
    "        plt.xlabel('Tasa de Falsos Positivos')\n",
    "        plt.ylabel('Tasa de Verdaderos Positivos')\n",
    "        plt.legend()\n",
    "        roc_plot_path = os.path.join(\"graficos\", f\"roc_curve_{os.path.basename(X_train_path)}.png\")\n",
    "        plt.savefig(roc_plot_path)\n",
    "        plt.close()\n",
    "\n",
    "        # Generar matriz de confusión detallada\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=np.unique(y_test), yticklabels=np.unique(y_test))\n",
    "        plt.title('Matriz de Confusión')\n",
    "        conf_matrix_path = os.path.join(\"graficos\", f\"conf_matrix_{os.path.basename(X_train_path)}.png\")\n",
    "        plt.savefig(conf_matrix_path)\n",
    "        plt.close()\n",
    "\n",
    "        # Resultados finales\n",
    "        end_time = datetime.now()\n",
    "        return {\n",
    "            'model_name': 'SGDClassifier-Optimizado',\n",
    "            'dataset': os.path.basename(X_train_path),\n",
    "            'start_time': start_time,\n",
    "            'end_time': end_time,\n",
    "            'duration': (end_time - start_time).total_seconds() / 60,\n",
    "            'avg_memory': np.mean(mem_tracking),\n",
    "            'test_accuracy': test_acc,\n",
    "            'test_precision': test_precision,\n",
    "            'test_recall': test_recall,\n",
    "            'test_f1': test_f1,\n",
    "            'classification_report': classification_report(y_test, y_pred, output_dict=True, zero_division=0),\n",
    "            'conf_matrix_path': conf_matrix_path,\n",
    "            'roc_curve_path': roc_plot_path,\n",
    "            'auc_scores': auc_scores,\n",
    "            'selected_features': len(selected_features)\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error procesando {X_train_path}: {str(e)}\")\n",
    "        return None\n",
    "    \n",
    "def generate_pdf_report(results, output_path):\n",
    "    \"\"\"Genera reporte PDF completo con análisis comparativo\"\"\"\n",
    "    csv_file = os.path.join(output_path, f\"metricas_completas_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\")\n",
    "    pdf_file = os.path.join(output_path, f\"reporte_completo_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pdf\")\n",
    "    \n",
    "    # Preparar datos para CSV\n",
    "    csv_data = []\n",
    "    best_models = {\n",
    "        'global': {'score': -1, 'model': None},\n",
    "        'class1_recall': {'score': -1, 'model': None},\n",
    "        'fastest': {'score': float('inf'), 'model': None},\n",
    "        'memory': {'score': float('inf'), 'model': None}\n",
    "    }\n",
    "    \n",
    "    for result in results:\n",
    "        if not result:\n",
    "            continue\n",
    "        \n",
    "        # Datos para CSV\n",
    "        model_data = {\n",
    "            'dataset': result['dataset'],\n",
    "            'inicio': result['start_time'].strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            'fin': result['end_time'].strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            'duracion_min': round(result['duration'], 2),\n",
    "            'memoria_promedio_gb': round(result['avg_memory'], 2),\n",
    "            'auc_promedio': round(np.mean(list(result['auc_scores'].values())), 3),\n",
    "            'test_accuracy': round(result['test_accuracy'], 3),\n",
    "            'test_precision': round(result['test_precision'], 3),\n",
    "            'test_recall': round(result['test_recall'], 3),\n",
    "            'test_f1': round(result['test_f1'], 3)\n",
    "        }\n",
    "        \n",
    "        # Métricas por clase\n",
    "        for cls, metrics in result['classification_report'].items():\n",
    "            if isinstance(metrics, dict):\n",
    "                for metric, value in metrics.items():\n",
    "                    if metric in ['precision', 'recall', 'f1-score', 'support']:\n",
    "                        model_data[f'clase{cls}_{metric}'] = round(value, 3)\n",
    "        \n",
    "        csv_data.append(model_data)\n",
    "        \n",
    "        # Actualizar mejores modelos\n",
    "        current_auc = model_data['auc_promedio']\n",
    "        current_recall = model_data.get('clase1_recall', 0)\n",
    "        \n",
    "        # Mejor modelo global\n",
    "        if current_auc > best_models['global']['score']:\n",
    "            best_models['global']['score'] = current_auc\n",
    "            best_models['global']['model'] = result\n",
    "            \n",
    "        # Mejor recall para clase 1\n",
    "        if current_recall > best_models['class1_recall']['score']:\n",
    "            best_models['class1_recall']['score'] = current_recall\n",
    "            best_models['class1_recall']['model'] = result\n",
    "            \n",
    "        # Modelo más rápido\n",
    "        if result['duration'] < best_models['fastest']['score']:\n",
    "            best_models['fastest']['score'] = result['duration']\n",
    "            best_models['fastest']['model'] = result\n",
    "            \n",
    "        # Menor uso de memoria\n",
    "        if result['avg_memory'] < best_models['memory']['score']:\n",
    "            best_models['memory']['score'] = result['avg_memory']\n",
    "            best_models['memory']['model'] = result\n",
    "    \n",
    "    # Generar CSV\n",
    "    pd.DataFrame(csv_data).to_csv(csv_file, index=False)\n",
    "    \n",
    "    # Generar PDF\n",
    "    c = canvas.Canvas(pdf_file, pagesize=letter)\n",
    "    y_position = 750\n",
    "    c.setFont(\"Helvetica-Bold\", 16)\n",
    "    c.drawString(100, y_position, \"Reporte Comparativo de Modelos\")\n",
    "    y_position -= 40\n",
    "    \n",
    "    # Tabla resumen\n",
    "    headers = ['Dataset', 'Duración (min)', 'Memoria (GB)', 'AUC Prom', 'Recall Clase 1']\n",
    "    col_widths = [120, 80, 80, 80, 100]\n",
    "    \n",
    "    # Encabezados de tabla\n",
    "    c.setFont(\"Helvetica-Bold\", 10)\n",
    "    x_pos = 50\n",
    "    for header, width in zip(headers, col_widths):\n",
    "        c.drawString(x_pos, y_position, header)\n",
    "        x_pos += width\n",
    "    y_position -= 20\n",
    "    \n",
    "    # Filas de datos\n",
    "    c.setFont(\"Helvetica\", 9)\n",
    "    for result in results:\n",
    "        if not result:\n",
    "            continue\n",
    "        \n",
    "        row_data = [\n",
    "            result['dataset'],\n",
    "            f\"{result['duration']:.2f}\",\n",
    "            f\"{result['avg_memory']:.2f}\",\n",
    "            f\"{np.mean(list(result['auc_scores'].values())):.2f}\",\n",
    "            f\"{result['classification_report'].get('1', {}).get('recall', 0):.2f}\"\n",
    "        ]\n",
    "        \n",
    "        x_pos = 50\n",
    "        for data, width in zip(row_data, col_widths):\n",
    "            c.drawString(x_pos, y_position, str(data))\n",
    "            x_pos += width\n",
    "        y_position -= 15\n",
    "        \n",
    "        if y_position < 100:\n",
    "            c.showPage()\n",
    "            y_position = 750\n",
    "    \n",
    "    # Sección de mejores modelos\n",
    "    c.setFont(\"Helvetica-Bold\", 14)\n",
    "    y_position -= 30\n",
    "    c.drawString(100, y_position, \"Mejores Modelos:\")\n",
    "    y_position -= 30\n",
    "    \n",
    "    best_categories = [\n",
    "        ('global', 'Mejor Modelo Global (AUC Promedio)'),\n",
    "        ('class1_recall', 'Mejor Recall para Clase 1'),\n",
    "        ('fastest', 'Modelo Más Rápido'),\n",
    "        ('memory', 'Menor Uso de Memoria')\n",
    "    ]\n",
    "    \n",
    "    for category, title in best_categories:\n",
    "        model = best_models[category]['model']\n",
    "        c.setFont(\"Helvetica-Bold\", 12)\n",
    "        c.drawString(120, y_position, title)\n",
    "        y_position -= 20\n",
    "        \n",
    "        if model:\n",
    "            c.setFont(\"Helvetica\", 10)\n",
    "            details = [\n",
    "                f\"Dataset: {model['dataset']}\",\n",
    "                f\"Duración: {model['duration']:.2f} min\",\n",
    "                f\"Memoria: {model['avg_memory']:.2f} GB\",\n",
    "                f\"AUC Prom: {np.mean(list(model['auc_scores'].values())):.2f}\",\n",
    "                f\"Recall Clase 1: {model['classification_report'].get('1', {}).get('recall', 0):.2f}\"\n",
    "            ]\n",
    "            for detail in details:\n",
    "                c.drawString(140, y_position, detail)\n",
    "                y_position -= 15\n",
    "        else:\n",
    "            c.drawString(140, y_position, \"N/A\")\n",
    "            y_position -= 15\n",
    "        \n",
    "        y_position -= 10\n",
    "        \n",
    "        if y_position < 100:\n",
    "            c.showPage()\n",
    "            y_position = 750\n",
    "    \n",
    "    # Gráficos comparativos\n",
    "    c.showPage()\n",
    "    y_position = 750\n",
    "    c.setFont(\"Helvetica-Bold\", 14)\n",
    "    c.drawString(100, y_position, \"Comparativa de Métricas\")\n",
    "    y_position -= 30\n",
    "    \n",
    "    # Generar y agregar gráficos comparativos\n",
    "    metrics = ['duration', 'avg_memory', 'auc_promedio']\n",
    "    for metric in metrics:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        values = [r[metric] for r in csv_data if metric in r]\n",
    "        labels = [r['dataset'] for r in csv_data if metric in r]\n",
    "        plt.barh(labels, values)\n",
    "        plt.title(f'Comparación de {metric.replace(\"_\", \" \").title()}')\n",
    "        plot_path = os.path.join(\"graficos\", f\"comparativa_{metric}.png\")\n",
    "        plt.savefig(plot_path, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        c.drawImage(plot_path, 50, y_position-250, width=500, height=200)\n",
    "        y_position -= 270\n",
    "        os.remove(plot_path)\n",
    "        \n",
    "        if y_position < 100:\n",
    "            c.showPage()\n",
    "            y_position = 750\n",
    "    \n",
    "    c.save()\n",
    "    \n",
    "    print(f\"\\nReportes generados:\\nCSV: {csv_file}\\nPDF: {pdf_file}\")\n",
    "    return csv_file, pdf_file\n",
    "\n",
    "def main():\n",
    "    input_root = r\"C:\\Users\\Administrador\\Documents\\PythonScripts\\Tesis\\tesisaustral\\outputs\\experiments\\train_test_splits_20250224_221733\"\n",
    "    output_root = os.path.join(input_root, \"reportes_modelos\")\n",
    "    os.makedirs(output_root, exist_ok=True)\n",
    "    \n",
    "    train_files = []\n",
    "    for root, _, files in os.walk(input_root):\n",
    "        for file in files:\n",
    "            if file.startswith(\"X_train\") and file.endswith(\".parquet\"):\n",
    "                base = file.replace(\"X_train_\", \"\").replace(\".parquet\", \"\")\n",
    "                required = {\n",
    "                    'X_train': file,\n",
    "                    'y_train': f\"y_train_{base}.parquet\",\n",
    "                    'X_test': f\"X_test_{base}.parquet\",\n",
    "                    'y_test': f\"y_test_{base}.parquet\"\n",
    "                }\n",
    "                \n",
    "                paths = {}\n",
    "                for k, v in required.items():\n",
    "                    full_path = os.path.join(root, v)\n",
    "                    if os.path.exists(full_path):\n",
    "                        paths[k] = full_path\n",
    "                    else:\n",
    "                        break\n",
    "                \n",
    "                if len(paths) == 4:\n",
    "                    train_files.append(paths)\n",
    "    \n",
    "    results = []\n",
    "    for dataset in train_files:\n",
    "        print(f\"\\nProcesando: {dataset['X_train']}\")\n",
    "        result = train_and_evaluate_model(\n",
    "            dataset['X_train'],\n",
    "            dataset['y_train'],\n",
    "            dataset['X_test'],\n",
    "            dataset['y_test']\n",
    "        )\n",
    "        if result:\n",
    "            results.append(result)\n",
    "            print(f\"✅ Procesado correctamente\")\n",
    "    \n",
    "    if results:\n",
    "        generate_pdf_report(results, output_root)\n",
    "    else:\n",
    "        print(\"\\n⚠️ No se encontraron resultados válidos\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Procesando: C:\\Users\\Administrador\\Documents\\PythonScripts\\Tesis\\tesisaustral\\outputs\\experiments\\train_test_splits_20250224_221733\\MaxAbs_full_full\\X_train_MaxAbs_full_full.parquet\n",
      "Calculando medianas...\n",
      "Selección inicial de características...\n",
      "Iniciando Grid Search...\n",
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n",
      "Mejores hiperparámetros: {'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Distribución de clases en el conjunto de prueba: {4: 31091, 1: 31091, 5: 31090, 3: 31090, 2: 31090}\n",
      "✅ Procesado correctamente\n",
      "\n",
      "Procesando: C:\\Users\\Administrador\\Documents\\PythonScripts\\Tesis\\tesisaustral\\outputs\\experiments\\train_test_splits_20250224_221733\\MaxAbs_Linear_selected\\X_train_MaxAbs_Linear_selected.parquet\n",
      "Calculando medianas...\n",
      "Selección inicial de características...\n",
      "Iniciando Grid Search...\n",
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n",
      "Mejores hiperparámetros: {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Distribución de clases en el conjunto de prueba: {4: 31091, 1: 31091, 5: 31090, 3: 31090, 2: 31090}\n",
      "✅ Procesado correctamente\n",
      "\n",
      "Procesando: C:\\Users\\Administrador\\Documents\\PythonScripts\\Tesis\\tesisaustral\\outputs\\experiments\\train_test_splits_20250224_221733\\MaxAbs_Model-Based_selected\\X_train_MaxAbs_Model-Based_selected.parquet\n",
      "Calculando medianas...\n",
      "Selección inicial de características...\n",
      "Iniciando Grid Search...\n",
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n",
      "Mejores hiperparámetros: {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Distribución de clases en el conjunto de prueba: {4: 31091, 1: 31091, 5: 31090, 3: 31090, 2: 31090}\n",
      "✅ Procesado correctamente\n",
      "\n",
      "Procesando: C:\\Users\\Administrador\\Documents\\PythonScripts\\Tesis\\tesisaustral\\outputs\\experiments\\train_test_splits_20250224_221733\\MaxAbs_Nonlinear_selected\\X_train_MaxAbs_Nonlinear_selected.parquet\n",
      "Calculando medianas...\n",
      "Selección inicial de características...\n",
      "Iniciando Grid Search...\n",
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n",
      "Mejores hiperparámetros: {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Distribución de clases en el conjunto de prueba: {4: 31091, 1: 31091, 5: 31090, 3: 31090, 2: 31090}\n",
      "✅ Procesado correctamente\n",
      "\n",
      "Procesando: C:\\Users\\Administrador\\Documents\\PythonScripts\\Tesis\\tesisaustral\\outputs\\experiments\\train_test_splits_20250224_221733\\MinMax_full_full\\X_train_MinMax_full_full.parquet\n",
      "Calculando medianas...\n",
      "Selección inicial de características...\n",
      "Iniciando Grid Search...\n",
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n",
      "Mejores hiperparámetros: {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Distribución de clases en el conjunto de prueba: {4: 31091, 1: 31091, 5: 31090, 3: 31090, 2: 31090}\n",
      "✅ Procesado correctamente\n",
      "\n",
      "Procesando: C:\\Users\\Administrador\\Documents\\PythonScripts\\Tesis\\tesisaustral\\outputs\\experiments\\train_test_splits_20250224_221733\\MinMax_Linear_selected\\X_train_MinMax_Linear_selected.parquet\n",
      "Calculando medianas...\n",
      "Selección inicial de características...\n",
      "Iniciando Grid Search...\n",
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n",
      "Mejores hiperparámetros: {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Distribución de clases en el conjunto de prueba: {4: 31091, 1: 31091, 5: 31090, 3: 31090, 2: 31090}\n",
      "✅ Procesado correctamente\n",
      "\n",
      "Procesando: C:\\Users\\Administrador\\Documents\\PythonScripts\\Tesis\\tesisaustral\\outputs\\experiments\\train_test_splits_20250224_221733\\MinMax_Model-Based_selected\\X_train_MinMax_Model-Based_selected.parquet\n",
      "Calculando medianas...\n",
      "Selección inicial de características...\n",
      "Iniciando Grid Search...\n",
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n",
      "Mejores hiperparámetros: {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Distribución de clases en el conjunto de prueba: {4: 31091, 1: 31091, 5: 31090, 3: 31090, 2: 31090}\n",
      "✅ Procesado correctamente\n",
      "\n",
      "Procesando: C:\\Users\\Administrador\\Documents\\PythonScripts\\Tesis\\tesisaustral\\outputs\\experiments\\train_test_splits_20250224_221733\\MinMax_Nonlinear_selected\\X_train_MinMax_Nonlinear_selected.parquet\n",
      "Calculando medianas...\n",
      "Selección inicial de características...\n",
      "Iniciando Grid Search...\n",
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n",
      "Mejores hiperparámetros: {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Distribución de clases en el conjunto de prueba: {4: 31091, 1: 31091, 5: 31090, 3: 31090, 2: 31090}\n",
      "✅ Procesado correctamente\n",
      "\n",
      "Procesando: C:\\Users\\Administrador\\Documents\\PythonScripts\\Tesis\\tesisaustral\\outputs\\experiments\\train_test_splits_20250224_221733\\NoNorm_full_full\\X_train_NoNorm_full_full.parquet\n",
      "Calculando medianas...\n",
      "Selección inicial de características...\n",
      "Iniciando Grid Search...\n",
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n",
      "Mejores hiperparámetros: {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Distribución de clases en el conjunto de prueba: {4: 31091, 1: 31091, 5: 31090, 3: 31090, 2: 31090}\n",
      "✅ Procesado correctamente\n",
      "\n",
      "Procesando: C:\\Users\\Administrador\\Documents\\PythonScripts\\Tesis\\tesisaustral\\outputs\\experiments\\train_test_splits_20250224_221733\\NoNorm_Linear_selected\\X_train_NoNorm_Linear_selected.parquet\n",
      "Calculando medianas...\n",
      "Selección inicial de características...\n",
      "Iniciando Grid Search...\n",
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n",
      "Mejores hiperparámetros: {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Distribución de clases en el conjunto de prueba: {4: 31091, 1: 31091, 5: 31090, 3: 31090, 2: 31090}\n",
      "✅ Procesado correctamente\n",
      "\n",
      "Procesando: C:\\Users\\Administrador\\Documents\\PythonScripts\\Tesis\\tesisaustral\\outputs\\experiments\\train_test_splits_20250224_221733\\NoNorm_Model-Based_selected\\X_train_NoNorm_Model-Based_selected.parquet\n",
      "Calculando medianas...\n",
      "Selección inicial de características...\n",
      "Iniciando Grid Search...\n",
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n",
      "Mejores hiperparámetros: {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Distribución de clases en el conjunto de prueba: {4: 31091, 1: 31091, 5: 31090, 3: 31090, 2: 31090}\n",
      "✅ Procesado correctamente\n",
      "\n",
      "Procesando: C:\\Users\\Administrador\\Documents\\PythonScripts\\Tesis\\tesisaustral\\outputs\\experiments\\train_test_splits_20250224_221733\\NoNorm_Nonlinear_selected\\X_train_NoNorm_Nonlinear_selected.parquet\n",
      "Calculando medianas...\n",
      "Selección inicial de características...\n",
      "Iniciando Grid Search...\n",
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n",
      "Mejores hiperparámetros: {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Distribución de clases en el conjunto de prueba: {4: 31091, 1: 31091, 5: 31090, 3: 31090, 2: 31090}\n",
      "✅ Procesado correctamente\n",
      "\n",
      "Procesando: C:\\Users\\Administrador\\Documents\\PythonScripts\\Tesis\\tesisaustral\\outputs\\experiments\\train_test_splits_20250224_221733\\Robust_Linear_selected\\X_train_Robust_Linear_selected.parquet\n",
      "Calculando medianas...\n",
      "Selección inicial de características...\n",
      "Iniciando Grid Search...\n",
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n",
      "Mejores hiperparámetros: {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Distribución de clases en el conjunto de prueba: {4: 31091, 1: 31091, 5: 31090, 3: 31090, 2: 31090}\n",
      "✅ Procesado correctamente\n",
      "\n",
      "Procesando: C:\\Users\\Administrador\\Documents\\PythonScripts\\Tesis\\tesisaustral\\outputs\\experiments\\train_test_splits_20250224_221733\\Robust_Model-Based_selected\\X_train_Robust_Model-Based_selected.parquet\n",
      "Calculando medianas...\n",
      "Selección inicial de características...\n",
      "Iniciando Grid Search...\n",
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n",
      "Mejores hiperparámetros: {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Distribución de clases en el conjunto de prueba: {4: 31091, 1: 31091, 5: 31090, 3: 31090, 2: 31090}\n",
      "✅ Procesado correctamente\n",
      "\n",
      "Procesando: C:\\Users\\Administrador\\Documents\\PythonScripts\\Tesis\\tesisaustral\\outputs\\experiments\\train_test_splits_20250224_221733\\Robust_Nonlinear_selected\\X_train_Robust_Nonlinear_selected.parquet\n",
      "Calculando medianas...\n",
      "Selección inicial de características...\n",
      "Iniciando Grid Search...\n",
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n",
      "Mejores hiperparámetros: {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Distribución de clases en el conjunto de prueba: {4: 31091, 1: 31091, 5: 31090, 3: 31090, 2: 31090}\n",
      "✅ Procesado correctamente\n",
      "\n",
      "Procesando: C:\\Users\\Administrador\\Documents\\PythonScripts\\Tesis\\tesisaustral\\outputs\\experiments\\train_test_splits_20250224_221733\\Standard_Linear_selected\\X_train_Standard_Linear_selected.parquet\n",
      "Calculando medianas...\n",
      "Selección inicial de características...\n",
      "Iniciando Grid Search...\n",
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n",
      "Mejores hiperparámetros: {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Distribución de clases en el conjunto de prueba: {4: 31091, 1: 31091, 5: 31090, 3: 31090, 2: 31090}\n",
      "✅ Procesado correctamente\n",
      "\n",
      "Procesando: C:\\Users\\Administrador\\Documents\\PythonScripts\\Tesis\\tesisaustral\\outputs\\experiments\\train_test_splits_20250224_221733\\Standard_Model-Based_selected\\X_train_Standard_Model-Based_selected.parquet\n",
      "Calculando medianas...\n",
      "Selección inicial de características...\n",
      "Iniciando Grid Search...\n",
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n",
      "Mejores hiperparámetros: {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "Distribución de clases en el conjunto de prueba: {4: 31091, 1: 31091, 5: 31090, 3: 31090, 2: 31090}\n",
      "✅ Procesado correctamente\n",
      "\n",
      "Procesando: C:\\Users\\Administrador\\Documents\\PythonScripts\\Tesis\\tesisaustral\\outputs\\experiments\\train_test_splits_20250224_221733\\Standard_Nonlinear_selected\\X_train_Standard_Nonlinear_selected.parquet\n",
      "Calculando medianas...\n",
      "Selección inicial de características...\n",
      "Iniciando Grid Search...\n",
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n",
      "Mejores hiperparámetros: {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Distribución de clases en el conjunto de prueba: {4: 31091, 1: 31091, 5: 31090, 3: 31090, 2: 31090}\n",
      "✅ Procesado correctamente\n",
      "\n",
      "Reportes generados:\n",
      "CSV: C:\\Users\\Administrador\\Documents\\PythonScripts\\Tesis\\tesisaustral\\outputs\\experiments\\train_test_splits_20250224_221733\\reportes_modelos\\metricas_completas_20250302_214958.csv\n",
      "PDF: C:\\Users\\Administrador\\Documents\\PythonScripts\\Tesis\\tesisaustral\\outputs\\experiments\\train_test_splits_20250224_221733\\reportes_modelos\\reporte_completo_20250302_214958.pdf\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import psutil\n",
    "import pyarrow.parquet as pq\n",
    "from datetime import datetime\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, roc_curve, auc,\n",
    "    accuracy_score, f1_score, precision_score, recall_score\n",
    ")\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def train_and_evaluate_model(X_train_path, y_train_path, X_test_path, y_test_path):\n",
    "    \"\"\"Entrena y evalúa un modelo Random Forest con Grid Search\"\"\"\n",
    "    start_time = datetime.now()\n",
    "    process = psutil.Process(os.getpid())\n",
    "    mem_before = process.memory_info().rss / (1024 ** 3)\n",
    "    \n",
    "    # Inicializar mem_tracking\n",
    "    mem_tracking = [mem_before]  # Incluir la memoria inicial\n",
    "    \n",
    "    try:\n",
    "        # 1. Cargar datos de entrenamiento\n",
    "        print(\"Cargando datos de entrenamiento...\")\n",
    "        X_train = pq.read_table(X_train_path).to_pandas()\n",
    "        y_train = pq.read_table(y_train_path).to_pandas().squeeze()\n",
    "\n",
    "        # Actualizar memoria\n",
    "        mem_tracking.append(process.memory_info().rss / (1024 ** 3))\n",
    "\n",
    "        # 2. Cargar datos de prueba\n",
    "        print(\"Cargando datos de prueba...\")\n",
    "        X_test = pq.read_table(X_test_path).to_pandas()\n",
    "        y_test = pq.read_table(y_test_path).to_pandas().squeeze()\n",
    "\n",
    "        # Actualizar memoria\n",
    "        mem_tracking.append(process.memory_info().rss / (1024 ** 3))\n",
    "\n",
    "        # 3. Verificar que las columnas de entrenamiento y prueba coincidan\n",
    "        missing_columns = set(X_train.columns) - set(X_test.columns)\n",
    "        if missing_columns:\n",
    "            print(f\"Advertencia: Columnas faltantes en X_test: {missing_columns}. Rellenando con 0.\")\n",
    "            for col in missing_columns:\n",
    "                X_test[col] = 0  # Rellenar con 0 o NaN según sea necesario\n",
    "\n",
    "        # 4. Selección de características\n",
    "        print(\"Selección inicial de características...\")\n",
    "        selector = SelectKBest(f_classif, k=min(100, X_train.shape[1]))\n",
    "        selector.fit(X_train, y_train)\n",
    "        selected_features = selector.get_support(indices=True)\n",
    "\n",
    "        # Actualizar memoria\n",
    "        mem_tracking.append(process.memory_info().rss / (1024 ** 3))\n",
    "\n",
    "        # 5. Configuración del modelo Random Forest\n",
    "        model = RandomForestClassifier(\n",
    "            class_weight='balanced',  # Balancear clases\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "        # 6. Definir la cuadrícula de hiperparámetros para Grid Search\n",
    "        param_grid = {\n",
    "            'n_estimators': [100, 200],  # Número de árboles\n",
    "            'max_depth': [None, 10, 20],  # Profundidad máxima de los árboles\n",
    "            'min_samples_split': [2, 5],  # Mínimo de muestras para dividir un nodo\n",
    "            'min_samples_leaf': [1, 2],  # Mínimo de muestras en una hoja\n",
    "            'max_features': ['sqrt', 'log2']  # Número de características a considerar en cada división\n",
    "        }\n",
    "\n",
    "        # 7. Configurar Grid Search\n",
    "        grid_search = GridSearchCV(\n",
    "            estimator=model,\n",
    "            param_grid=param_grid,\n",
    "            scoring='f1_macro',  # Métrica a optimizar\n",
    "            cv=3,  # Validación cruzada de 3 folds\n",
    "            n_jobs=-1,  # Usar todos los núcleos disponibles\n",
    "            verbose=2\n",
    "        )\n",
    "\n",
    "        # 8. Aplicar SMOTE solo en el conjunto de entrenamiento\n",
    "        smote = SMOTE(sampling_strategy='auto', k_neighbors=3, random_state=42)\n",
    "        X_res, y_res = smote.fit_resample(X_train.iloc[:, selected_features], y_train)\n",
    "\n",
    "        # Actualizar memoria\n",
    "        mem_tracking.append(process.memory_info().rss / (1024 ** 3))\n",
    "\n",
    "        # 9. Entrenar el modelo con Grid Search\n",
    "        print(\"Iniciando Grid Search...\")\n",
    "        grid_search.fit(X_res, y_res)\n",
    "\n",
    "        # Actualizar memoria\n",
    "        mem_tracking.append(process.memory_info().rss / (1024 ** 3))\n",
    "\n",
    "        # 10. Mejor modelo encontrado\n",
    "        best_model = grid_search.best_estimator_\n",
    "        print(f\"Mejores hiperparámetros: {grid_search.best_params_}\")\n",
    "\n",
    "        # 11. Evaluación final\n",
    "        y_pred = best_model.predict(X_test.iloc[:, selected_features])\n",
    "        y_proba = best_model.predict_proba(X_test.iloc[:, selected_features])\n",
    "        \n",
    "        # Verificar que y_proba no contenga NaN o infinitos\n",
    "        if np.isnan(y_proba).any() or np.isinf(y_proba).any():\n",
    "            raise ValueError(\"Las probabilidades predichas contienen NaN o infinitos. Revisa el entrenamiento del modelo.\")\n",
    "        \n",
    "        # Verificar la distribución de clases en el conjunto de prueba\n",
    "        class_distribution_test = y_test.value_counts()\n",
    "        print(\"Distribución de clases en el conjunto de prueba:\", class_distribution_test.to_dict())\n",
    "        \n",
    "        # Filtrar clases con menos de 2 muestras\n",
    "        valid_classes = class_distribution_test[class_distribution_test >= 2].index\n",
    "        \n",
    "        # Calcular la matriz de confusión\n",
    "        conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "        \n",
    "        # Generar curvas ROC para todas las clases\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        auc_scores = {}\n",
    "        for i in valid_classes:\n",
    "            try:\n",
    "                # Ajustar el índice para coincidir con la columna de y_proba\n",
    "                col_idx = i - 1  # Restar 1 para convertir de índice 1-5 a índice 0-4\n",
    "                fpr, tpr, _ = roc_curve((y_test == i).astype(int), y_proba[:, col_idx])\n",
    "                auc_value = auc(fpr, tpr)\n",
    "                auc_scores[f\"Clase {i}\"] = auc_value\n",
    "                plt.plot(fpr, tpr, label=f'Clase {i} (AUC = {auc_value:.2f})')\n",
    "            except ValueError as e:\n",
    "                print(f\"Error calculando AUC para la clase {i}: {str(e)}\")\n",
    "                auc_scores[f\"Clase {i}\"] = np.nan\n",
    "\n",
    "        # Verificar si se pudo calcular al menos un AUC válido\n",
    "        if not auc_scores or all(np.isnan(value) for value in auc_scores.values()):\n",
    "            print(\"No se pudo calcular el AUC para ninguna clase. Generando gráfico vacío.\")\n",
    "            plt.text(0.5, 0.5, 'No se pudo calcular el AUC para ninguna clase', ha='center', va='center')\n",
    "        \n",
    "        plt.title('Curvas ROC')\n",
    "        plt.xlabel('Tasa de Falsos Positivos')\n",
    "        plt.ylabel('Tasa de Verdaderos Positivos')\n",
    "        plt.legend()\n",
    "        roc_plot_path = os.path.join(\"graficos\", f\"roc_curve_{os.path.basename(X_train_path)}.png\")\n",
    "        plt.savefig(roc_plot_path)\n",
    "        plt.close()\n",
    "\n",
    "        # Generar matriz de confusión detallada\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=np.unique(y_test), yticklabels=np.unique(y_test))\n",
    "        plt.title('Matriz de Confusión')\n",
    "        conf_matrix_path = os.path.join(\"graficos\", f\"conf_matrix_{os.path.basename(X_train_path)}.png\")\n",
    "        plt.savefig(conf_matrix_path)\n",
    "        plt.close()\n",
    "\n",
    "        # Resultados finales\n",
    "        end_time = datetime.now()\n",
    "        return {\n",
    "            'model_name': 'RandomForest-Optimizado',\n",
    "            'dataset': os.path.basename(X_train_path),\n",
    "            'start_time': start_time,\n",
    "            'end_time': end_time,\n",
    "            'duration': (end_time - start_time).total_seconds() / 60,\n",
    "            'avg_memory': np.mean(mem_tracking),\n",
    "            'test_accuracy': accuracy_score(y_test, y_pred),\n",
    "            'test_precision': precision_score(y_test, y_pred, average='macro'),\n",
    "            'test_recall': recall_score(y_test, y_pred, average='macro'),\n",
    "            'test_f1': f1_score(y_test, y_pred, average='macro'),\n",
    "            'classification_report': classification_report(y_test, y_pred, output_dict=True, zero_division=0),\n",
    "            'conf_matrix_path': conf_matrix_path,\n",
    "            'roc_curve_path': roc_plot_path,\n",
    "            'auc_scores': auc_scores,\n",
    "            'selected_features': len(selected_features),\n",
    "            'best_params': grid_search.best_params_\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error procesando {X_train_path}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def main():\n",
    "    input_root = r\"C:\\Users\\Administrador\\Documents\\PythonScripts\\Tesis\\tesisaustral\\outputs\\experiments\\train_test_splits_20250224_221733\"\n",
    "    output_root = os.path.join(input_root, \"reportes_modelos\")\n",
    "    os.makedirs(output_root, exist_ok=True)\n",
    "    \n",
    "    train_files = []\n",
    "    for root, _, files in os.walk(input_root):\n",
    "        for file in files:\n",
    "            if file.startswith(\"X_train\") and file.endswith(\".parquet\"):\n",
    "                base = file.replace(\"X_train_\", \"\").replace(\".parquet\", \"\")\n",
    "                required = {\n",
    "                    'X_train': file,\n",
    "                    'y_train': f\"y_train_{base}.parquet\",\n",
    "                    'X_test': f\"X_test_{base}.parquet\",\n",
    "                    'y_test': f\"y_test_{base}.parquet\"\n",
    "                }\n",
    "                \n",
    "                paths = {}\n",
    "                for k, v in required.items():\n",
    "                    full_path = os.path.join(root, v)\n",
    "                    if os.path.exists(full_path):\n",
    "                        paths[k] = full_path\n",
    "                    else:\n",
    "                        break\n",
    "                \n",
    "                if len(paths) == 4:\n",
    "                    train_files.append(paths)\n",
    "    \n",
    "    results = []\n",
    "    for dataset in train_files:\n",
    "        print(f\"\\nProcesando: {dataset['X_train']}\")\n",
    "        result = train_and_evaluate_model(\n",
    "            dataset['X_train'],\n",
    "            dataset['y_train'],\n",
    "            dataset['X_test'],\n",
    "            dataset['y_test']\n",
    "        )\n",
    "        if result:\n",
    "            results.append(result)\n",
    "            print(f\"✅ Procesado correctamente\")\n",
    "    \n",
    "    if results:\n",
    "        generate_pdf_report(results, output_root)\n",
    "    else:\n",
    "        print(\"\\n⚠️ No se encontraron resultados válidos\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, MaxAbsScaler, RobustScaler\n",
    "\n",
    "# Cargar configuración\n",
    "with open(\"config.json\", \"r\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "base_path = os.getcwd()\n",
    "data_path = os.path.join(base_path, config[\"paths\"][\"data\"])\n",
    "normalized_path = os.path.join(base_path, config[\"paths\"][\"normalized\"])\n",
    "os.makedirs(normalized_path, exist_ok=True)\n",
    "\n",
    "# Cargar dataset original\n",
    "dataset_file = os.path.join(data_path, config[\"parameters\"][\"dataset_file\"])\n",
    "df = pd.read_parquet(dataset_file)\n",
    "\n",
    "# Columnas para normalizar\n",
    "columns_to_normalize = config[\"parameters\"][\"columns_to_normalize\"]\n",
    "\n",
    "# Métodos de normalización\n",
    "scalers = {\n",
    "    \"maxabs\": MaxAbsScaler(),\n",
    "    \"minmax\": MinMaxScaler(),\n",
    "    \"standard\": StandardScaler(),\n",
    "    \"robust\": RobustScaler(),\n",
    "    \"none\": None  # Sin normalización\n",
    "}\n",
    "\n",
    "# Aplicar normalizaciones\n",
    "for method, scaler in scalers.items():\n",
    "    df_normalized = df.copy()\n",
    "    if scaler is not None:\n",
    "        df_normalized[columns_to_normalize] = scaler.fit_transform(df[columns_to_normalize])\n",
    "    # Guardar resultados\n",
    "    output_file = os.path.join(normalized_path, f\"02_df_{method.capitalize()}.parquet\")\n",
    "    df_normalized.to_parquet(output_file, index=False)\n",
    "    print(f\"Dataset normalizado guardado en: {output_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
